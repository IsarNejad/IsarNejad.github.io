---
layout: archive
title: ""
permalink: /research/
author_profile: true
---


# AI for Social Good
  - [**Multimodal social media analysis for disaster response:**](#MultiModal-Disaster) This project is funded by New Beginning Initiative Program and is in collaboration with Carleton University. 
  - **Innovative solutions to improve the immigration system in Canada:** This project is in collaboration with MILA institute and focuses on using AI to make the immigration settlement in Canada more efficient. 
  - [**Detecting and countering stereotypes:**](#Det-Count-Stereo) This project focuses on detecting abusive language on social media and countering it using NLP models.
    
# Computational Social Science
  - **Stereotypes in natural language:** In this project, we use computational linguistics and machine learning techniques to uncover and combat the stereotypical views prominent in society. 
  - **Political ideology detection on social media:** This project is in collaboration with McGill University, where we use network analysis and natural language processing to understand the political ideologies expressed on social media.
    
# Explainability and Fairness in NLP
  - **Concept-based explanations:** In this project, we use concept-based explanations to analyze a model with respect to its sensitivity to human-understandable concepts. 
  - **Bias in NLP models:** In this project, we use different techniques to uncover biases in text classifiers and generative models.
    
# Machine Learning Applications
  - **Medical data analysis**
  - **Audio and speech processing**
  - **Facial recognition**
    
---

{: .underline-blue}
## Multimodal social media analysis for disaster response:
<a id="MultiModal-Disaster"></a>

## Detecting and countering stereotypes:
<a id="Det-Count-Stereo"></a>

1. Fraser, K. C., Kiritchenko, S., & Nejadgholi, I. (2022). Computational modeling of stereotype content in text. Frontiers in artificial intelligence, 5, 826207. [Link](https://www.frontiersin.org/articles/10.3389/frai.2022.826207/full)
